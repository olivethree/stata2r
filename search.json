[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Cookbook Data Analysis with Stata and R",
    "section": "",
    "text": "Welcome\nWelcome to the “Cookbook Data Analysis with Stata and R”! This book is designed to be your comprehensive guide to mastering data analysis using two of the most powerful tools available: Stata and R. Whether you are a beginner or have some experience, this book will help you develop the skills needed to tackle a wide range of data analysis challenges.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#why-this-book",
    "href": "index.html#why-this-book",
    "title": "Cookbook Data Analysis with Stata and R",
    "section": "Why This Book?",
    "text": "Why This Book?\nIn the Human Technology Interaction track at TU/e, understanding and analyzing data is crucial. This book aims to provide you with practical, hands-on experience in data analysis, tailored specifically to the needs of your coursework and future career. By the end of this book, you will be able to:\n\nImport and manage data in both Stata and R.\nClean and prepare your data for analysis.\nPerform a variety of statistical analyses.\nVisualize your data to uncover insights.\nCommunicate your findings effectively.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#what-you-will-learn",
    "href": "index.html#what-you-will-learn",
    "title": "Cookbook Data Analysis with Stata and R",
    "section": "What You Will Learn",
    "text": "What You Will Learn\nData analysis is a vast field, and this book focuses on giving you a solid foundation in the most essential tools and techniques. Here’s what you can expect to learn:\n\nData Import and Management: Learn how to import data from various sources and manage it efficiently in Stata and R.\nData Cleaning and Preparation: Understand the importance of tidy data and how to clean and prepare your datasets for analysis.\nStatistical Analysis: Perform descriptive and inferential statistics to draw meaningful conclusions from your data.\nData Visualization: Create compelling visualizations to explore and present your data.\nReproducible Research: Learn best practices for ensuring your analyses are reproducible and transparent.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#simulated-data-sets-for-real-world-scenarios",
    "href": "index.html#simulated-data-sets-for-real-world-scenarios",
    "title": "Cookbook Data Analysis with Stata and R",
    "section": "Simulated data sets for real world scenarios",
    "text": "Simulated data sets for real world scenarios\nThroughout this book, you will work on simulated data sets (this means they are not based on real data) aiming to reflect real-world examples and case studies relevant to Human Technology Interaction. These examples will help you see how the techniques you learn can be applied to actual research and industry scenarios. Whether you are analyzing user behavior, evaluating the effectiveness of a new technology, or exploring human-computer interaction, this book will provide you with the most commonly used tools you need.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#getting-started",
    "href": "index.html#getting-started",
    "title": "Cookbook Data Analysis with Stata and R",
    "section": "Getting Started",
    "text": "Getting Started\nTo get the most out of this book, you will need to have Stata and R installed on your computer. Familiarity with basic statistical concepts will be helpful, but not required, as we will cover the necessary background along the way.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "1.1 Brief History of R and Stata",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#r",
    "href": "intro.html#r",
    "title": "1  Introduction",
    "section": "1.2 R",
    "text": "1.2 R\nR is a programming language and free software environment for statistical computing and graphics. It was created by Ross Ihaka and Robert Gentleman at the University of Auckland, New Zealand, and the first public announcement of R was made in 1993 1(Peng 2016). The language was inspired by the S language, which was developed at Bell Laboratories. R has since become a popular tool among statisticians and data scientists due to its extensive package ecosystem and active user community.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#stata",
    "href": "intro.html#stata",
    "title": "1  Introduction",
    "section": "1.3 Stata",
    "text": "1.3 Stata\nStata is a general-purpose statistical software package created in the mid-1980s by William Gould, a UCLA graduate, and Sean Becketti 2(Cox 2005). Initially developed within the Computing Resource Center (CRC) in Santa Monica, California, Stata was designed to provide a powerful yet user-friendly environment for data analysis. The first version of Stata was released in 1985, and it has since evolved to include a wide range of statistical, graphical, and data management capabilities.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#comparison-of-r-and-stata",
    "href": "intro.html#comparison-of-r-and-stata",
    "title": "1  Introduction",
    "section": "1.4 Comparison of R and Stata",
    "text": "1.4 Comparison of R and Stata\n\n\n\n\n\n\n\n\nFeature\nR\nStata\n\n\n\n\nCost\nFree and open-source\nPaid software\n\n\nUser Interface\nCommand-line interface, with various IDEs like RStudio available\nUser-friendly GUI and command-line interface\n\n\nFlexibility\nHighly flexible, suitable for custom analyses and new methods\nLess flexible, but highly efficient for standard statistical tasks\n\n\nPackages\nExtensive package ecosystem for various analyses and visualizations\nComprehensive built-in functions and user-written commands\n\n\nLearning Curve\nSteeper learning curve, especially for beginners\nEasier to learn, with simpler syntax\n\n\nCommunity Support\nLarge, active community with extensive online resources\nSmaller community, but excellent official documentation\n\n\nReproducibility\nStrong support for reproducible research through RMarkdown and other tools\nGood support for reproducibility, but less integrated than R\n\n\nData Management\nPowerful data manipulation capabilities with packages like dplyr\nEfficient data manipulation and management built-in\n\n\nVisualization\nAdvanced visualization capabilities with ggplot2 and other packages\nGood visualization tools, but less flexible than R\n\n\n\n\n\n\n\nCox, Nicholas J. 2005. “A Brief History of Stata on Its 20th Anniversary.” The Stata Journal: Promoting Communications on Statistics and Stata 5 (1): 2–18. https://doi.org/10.1177/1536867x0500500102.\n\n\nPeng, Roger D. 2016. R Programming for Data Science. Leanpub Victoria, BC, Canada.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#footnotes",
    "href": "intro.html#footnotes",
    "title": "1  Introduction",
    "section": "",
    "text": "Peng, Roger D. 2016. R Programming for Data Science. LeanpubVictoria, BC, Canada.↩︎\nCox, Nicholas J. 2005. “A Brief History of Stata on Its 20thAnniversary.” The Stata Journal: Promoting Communications onStatistics and Stata 5 (1): 2–18. https://doi.org/10.1177/1536867x0500500102.↩︎",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "getting_started.html",
    "href": "getting_started.html",
    "title": "2  Getting Started",
    "section": "",
    "text": "2.1 Introduction\nThis chapter provides a quick tutorial on how to install and set up R and Stata on both Windows and Mac computers. By the end of this chapter, you’ll have the necessary tools ready to begin your analysis.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting Started</span>"
    ]
  },
  {
    "objectID": "getting_started.html#installing-r",
    "href": "getting_started.html#installing-r",
    "title": "2  Getting Started",
    "section": "2.2 Installing R",
    "text": "2.2 Installing R\n\n2.2.1 Windows\n\nDownload R:\n\nGo to the R Project website.\nClick on “Download R for Windows.”\nClick on “base” to download the base R package.\n\nInstall R:\n\nRun the downloaded .exe file.\nFollow the installation instructions, accepting the default settings.\n\nInstall RStudio (Optional but recommended):\n\nDownload RStudio from the RStudio website.\nRun the installer and follow the setup instructions.\n\n\n\n\n2.2.2 Mac\n\nDownload R:\n\nVisit the R Project website.\nClick on “Download R for macOS.”\n\nInstall R:\n\nOpen the downloaded .pkg file.\nFollow the installation instructions.\n\nInstall RStudio (Optional but recommended):\n\nDownload RStudio from the RStudio website.\nOpen the .dmg file and drag RStudio to your Applications folder.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting Started</span>"
    ]
  },
  {
    "objectID": "getting_started.html#installing-stata",
    "href": "getting_started.html#installing-stata",
    "title": "2  Getting Started",
    "section": "2.3 Installing Stata",
    "text": "2.3 Installing Stata\n\n2.3.1 Windows\n\nObtain a License:\n\nStata is (unfortunately) commercial software. You need a valid license. Look it up in your course page or ask your teacher.\n\nDownload Stata:\n\nGo to the Stata website and log in to your account to download the installer.\n\nInstall Stata:\n\nRun the downloaded .exe file.\nFollow the installation instructions, entering your license information when asked for it.\n\n\n\n\n2.3.2 Mac\n\nObtain a License:\n\nStata is (unfortunately) commercial software. You need a valid license. Look it up in your course page or ask your teacher.\n\nDownload Stata:\n\nVisit the Stata website and log in to your account to download the installer.\n\nInstall Stata:\n\nOpen the downloaded .dmg file.\nDrag the Stata application to your Applications folder.\nLaunch Stata and enter your license information.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting Started</span>"
    ]
  },
  {
    "objectID": "getting_started.html#setting-up-your-environment",
    "href": "getting_started.html#setting-up-your-environment",
    "title": "2  Getting Started",
    "section": "2.4 Setting Up Your Environment",
    "text": "2.4 Setting Up Your Environment\n\n2.4.1 R Setup\n\nOpen RStudio (or R GUI if not using RStudio).\nInstall Essential Packages:\n\nOpen the Console and run:\n\n\n\n   install.packages(c(\"tidyverse\", \"magrittr\", \"here\"))\n\n\nCreate a New Project (Optional but recommended in RStudio):\n\nGo to “File” &gt; “New Project” &gt; “New Directory” &gt; “New Project.”\nChoose a location and name for your project, then click “Create Project.”\n\n\n\n\n2.4.2 Stata Setup\n\nOpen Stata.\nSet a Working Directory:\n\nUse the command:\n\n\n   cd \"path/to/your/directory\"\n\nReplace \"path/to/your/directory\" with the path where you want to save your files.\nCreating Do-Files:\n\nGo to “File” &gt; “New Do-file Editor.”\nSave the Do-file in your working directory.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting Started</span>"
    ]
  },
  {
    "objectID": "getting_started.html#verification",
    "href": "getting_started.html#verification",
    "title": "2  Getting Started",
    "section": "2.5 Verification",
    "text": "2.5 Verification\n\n2.5.1 R\n\nTest Installation:\n\nIn RStudio or R GUI, type:\n\n\n   print(\"R is working! Yay!\")\n\n\nIf you see the output [1] \"R is working!\", your installation is successful.\n\nLoad a Package:\n\nRun:\n\n\n   library(ggplot2)\n   print(\"Package 'ggplot2' is loaded!\")\n\n\n\n\n2.5.2 Stata\n\nTest Installation:\n\nIn the Command window, type:\n\n\n   display \"Stata is working! Yay!\"\n\n\nIf you see the output Stata is working!, your installation is successful.\n\nCheck Version:\n\nType:\n\n\n   about\n\n\nThis will display the version of Stata installed.\n\n\n\nWith your environment set up, you’re now ready to start performing analyses using R and Stata!",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting Started</span>"
    ]
  },
  {
    "objectID": "ttest.html",
    "href": "ttest.html",
    "title": "3  t-test",
    "section": "",
    "text": "3.1 Brief Explanation\nThe t-test, proposed by William Sealy Gosset under the pseudonym “Student” in 1908 (Student 1908) 1 (Ziliak 2008) 2,is used to determine if there is a significant difference between the means of two groups. The t-test is applicable in various scenarios, including both small and large sample sizes, particularly when the population variance is unknown. The t-test assumes that the data is approximately normally distributed.\nThere are two main types of t-tests commonly used:",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>t-test</span>"
    ]
  },
  {
    "objectID": "ttest.html#brief-explanation",
    "href": "ttest.html#brief-explanation",
    "title": "3  t-test",
    "section": "",
    "text": "Independent Samples t-test: Compares the means of two independent groups (between-subjects design).\nPaired Samples t-test: Compares means from the same group at different times or under different conditions (within-subjects design).\n\n\n3.1.1 Understanding Independent and Dependent Data\n\nIndependent data: In an independent samples t-test, the data from the two groups are independent, meaning that there is no inherent relationship between the observations in one group and the observations in the other group. This is typical of a between-subjects design, where different participants are assigned to different conditions.\nDependent data: In a paired samples t-test, the data are dependent, meaning that each observation in one condition is paired with an observation in another condition. This is typical of a within-subjects design, where the same participants are measured under different conditions or at different times.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>t-test</span>"
    ]
  },
  {
    "objectID": "ttest.html#research-scenario",
    "href": "ttest.html#research-scenario",
    "title": "3  t-test",
    "section": "3.2 Research Scenario",
    "text": "3.2 Research Scenario\nImagine a tech company, “BeautifulWeb,” which has recently launched a new interface design for its flagship software. The company is keen to understand whether this new design truly enhances user satisfaction compared to the old design. The company has two different research questions:\n\nIndependent Samples Scenario: BeautifulWeb randomly assigns users to use either the old or the new design and then measures their satisfaction. The research question is: Does the new interface design improve user satisfaction compared to the old design?\nPaired Samples Scenario: BeautifulWeb asks the same users to use both the old and new designs at different times and then measures their satisfaction. The research question is: Does user satisfaction improve after using the new interface design compared to the old design?",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>t-test</span>"
    ]
  },
  {
    "objectID": "ttest.html#independent-samples-t-test",
    "href": "ttest.html#independent-samples-t-test",
    "title": "3  t-test",
    "section": "3.3 Independent Samples t-test",
    "text": "3.3 Independent Samples t-test\n\n3.3.1 Research Question\nDoes the new interface design improve user satisfaction compared to the old design?\nHypotheses\n\nNull Hypothesis (H₀): There is no significant difference in user satisfaction scores between the old and new interface designs.\nAlternative Hypothesis (H₁): Users report higher satisfaction scores with the new interface design compared to the old design.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>t-test</span>"
    ]
  },
  {
    "objectID": "ttest.html#technical-requirements",
    "href": "ttest.html#technical-requirements",
    "title": "3  t-test",
    "section": "3.4 Technical Requirements",
    "text": "3.4 Technical Requirements\nBefore we start, we need to prepare R and Stata (but mostly R, really) for the specific analysis we are focusing on. This implies loading any required packages typically used for these analyses, or ones that are useful to process the data (cleaning, shapng, tidying, transforming, etc.).\n\n3.4.1 Stata\nNo specific Stata libraries need to be installed. All that you need should be available by default in Stata.\n\n\n3.4.2 R\n\n# Load the necessary packages \nlibrary(tidyverse) # used for data manipulation and visualization\nlibrary(ggthemes) # adds new plotting themes for data visualization\nlibrary(cowplot) # nice plot theme and makes it easier to adjust plot text features\nlibrary(effsize) # for effect size calculations\n\n# to install any missing packages go to the Terminal and run the command: install.packages(\"PACKAGE_NAME\")",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>t-test</span>"
    ]
  },
  {
    "objectID": "ttest.html#independent-samples-t-test-1",
    "href": "ttest.html#independent-samples-t-test-1",
    "title": "3  t-test",
    "section": "3.5 Independent Samples t-test",
    "text": "3.5 Independent Samples t-test\n\n3.5.1 Simulate Data\nInstead of relying on existng datasets with real data, we will generate our own data sets with fake data. These data were generated to reflect the research scenario in this chapter. This also means that these data are not real and therefore any conclusions drawn from the analyses are invalid, and serve only for educational purposes.\nBy generating a fake dataset, you are also learning how to do Data Simulation, something that might come in handy in the future if you need to conduct statistical power analyses, or create datasets to provide examples of your analyses in help-seeking contexts without having to share any sensitive real data (e.g., when asking for help with your code in platforms such as https://stats.stackexchange.com/).\n\n3.5.1.1 Stata\n\nclear\nset seed 123\nset obs 60\ngen group = cond(_n &lt;= 30, \"Old Design\", \"New Design\")\ngen satisfaction = rnormal(70 + 5 * (group == \"New Design\"), 10)\nsave satisfaction_data_independent.dta, replace\n\nNumber of observations (_N) was 0, now 60.\n\n\n\nfile satisfaction_data_independent.dta saved\n\n\n\n\n3.5.1.2 R\n\nset.seed(123)\nn &lt;- 30\nold_design &lt;- rnorm(n, mean = 70, sd = 10)\nnew_design &lt;- rnorm(n, mean = 75, sd = 10)\nstudydata &lt;- data.frame(\n  group = rep(c(\"Old Design\", \"New Design\"), each = n),\n  satisfaction = c(old_design, new_design)\n)\nwrite.csv(studydata, \"satisfaction_data_independent.csv\", row.names = FALSE)\n\n\n\n\n3.5.2 Descriptives and data visualization\n\n3.5.2.1 Stata\n\nuse satisfaction_data_independent.dta\nsummarize satisfaction\ngraph box satisfaction, over(group)\n\n    Variable |        Obs        Mean    Std. dev.       Min        Max\n-------------+---------------------------------------------------------\nsatisfaction |         60    72.01051    11.46396   28.95397   95.01126\n\n\n\n\n\n3.5.2.2 R\n\n# Import data\nstudydata &lt;- read.csv(\"satisfaction_data_independent.csv\") \n\n# Summary of data\nsummary(studydata$satisfaction)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  50.33   65.48   73.26   73.16   80.62   96.69 \n\n\n\nggplot(studydata, aes(x = group, y = satisfaction, fill = group)) +\n  geom_boxplot(outlier.color = \"red\", outlier.shape = 16, outlier.size = 2) +\n  scale_fill_brewer(palette = \"Set3\") +\n  theme_cowplot() +\n  labs(\n    title = \"Satisfaction Scores by Design Group\",\n    x = \"Design Group\",\n    y = \"Satisfaction Score\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n3.5.3 Performing the t-test\nImportant Note About R’s t-test\nBy default, R uses Welch’s t-test, which does not assume equal variances between the groups. This is often a more robust approach, but if you want to match the classical t-test calculation (assuming equal variances), you need to specify var.equal = TRUE in the t.test() function. The code provided here uses the classical approach to ensure it matches the Stata output.\n\n3.5.3.1 Stata\n\nuse satisfaction_data_independent.dta\nttest satisfaction, by(group)\n\nTwo-sample t test with equal variances\n------------------------------------------------------------------------------\n   Group |     Obs        Mean    Std. err.   Std. dev.   [95% conf. interval]\n---------+--------------------------------------------------------------------\nNew Desi |      30    73.71915    2.408986    13.19456    68.79222    78.64608\nOld Desi |      30    70.30186    1.705283    9.340221    66.81417    73.78956\n---------+--------------------------------------------------------------------\nCombined |      60    72.01051     1.47999    11.46396    69.04905    74.97196\n---------+--------------------------------------------------------------------\n    diff |             3.41729    2.951475               -2.490729    9.325309\n------------------------------------------------------------------------------\n    diff = mean(New Desi) - mean(Old Desi)                        t =   1.1578\nH0: diff = 0                                     Degrees of freedom =       58\n\n    Ha: diff &lt; 0                 Ha: diff != 0                 Ha: diff &gt; 0\n Pr(T &lt; t) = 0.8742         Pr(|T| &gt; |t|) = 0.2517          Pr(T &gt; t) = 0.1258\n\n\n\n\n3.5.3.2 R\n\nt.test(satisfaction ~ group, data = studydata, var.equal = TRUE)\n\n\n    Two Sample t-test\n\ndata:  satisfaction by group\nt = 3.0841, df = 58, p-value = 0.003125\nalternative hypothesis: true difference in means between group New Design and group Old Design is not equal to 0\n95 percent confidence interval:\n  2.545972 11.962870\nsample estimates:\nmean in group New Design mean in group Old Design \n                76.78338                 69.52896 \n\n\n\n\n\n3.5.4 Interpretation\n\nP-value: Indicates whether the difference in means is statistically significant.\nConfidence Interval: By default, this is a 95% confidence interval, but you can adjust this with the conf.level parameter in the t.test() function.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>t-test</span>"
    ]
  },
  {
    "objectID": "ttest.html#paired-samples-t-test",
    "href": "ttest.html#paired-samples-t-test",
    "title": "3  t-test",
    "section": "3.6 Paired Samples t-test",
    "text": "3.6 Paired Samples t-test\n\n3.6.1 Research Question\nResearch Question: Does user satisfaction improve after using the new interface design compared to the old design?\nHypothesis\n\nNull Hypothesis (H₀): There is no significant difference in user satisfaction scores before and after using the new interface design.\nAlternative Hypothesis (H₁): Users report higher satisfaction scores after using the new interface design compared to before.\n\n\n\n3.6.2 Simulate Data\n\n3.6.2.1 Stata\n\nclear\nset seed 123\nset obs 30\ngen user_id = _n\ngen before_update = rnormal(70, 10)\ngen after_update = rnormal(75, 10)\nsave satisfaction_data_paired.dta, replace\n\nNumber of observations (_N) was 0, now 30.\n\n\n\n\nfile satisfaction_data_paired.dta saved\n\n\n\n\n3.6.2.2 R\n\nset.seed(123)\nn &lt;- 30\nbefore_update &lt;- rnorm(n, mean = 70, sd = 10)\nafter_update &lt;- rnorm(n, mean = 75, sd = 10)\nstudydata &lt;- data.frame(\n  user_id = 1:n,\n  before_update = before_update,\n  after_update = after_update\n)\nwrite.csv(studydata, \"satisfaction_data_paired.csv\", row.names = FALSE)\n\n\n\n\n3.6.3 Descriptives and data visualization\n\n3.6.3.1 Stata\n\nuse satisfaction_data_paired.dta\nsummarize before_update after_update\ngraph box before_update after_update, title(\"Satisfaction Scores Before and After Update\") ytitle(\"Satisfaction Score\") b1title(\"Update Status\") nooutsides\n\n    Variable |        Obs        Mean    Std. dev.       Min        Max\n-------------+---------------------------------------------------------\nbefore_upd~e |         30    70.30186    9.340221   52.33546   91.09727\nafter_update |         30    73.71915    13.19456   28.95397   95.01126\n\n\n\n\n3.6.3.2 \n\n\n3.6.3.3 R\n\nstudydata &lt;- read.csv(\"satisfaction_data_paired.csv\")\nsummary(studydata[, c(\"before_update\", \"after_update\")])\n\n before_update    after_update  \n Min.   :50.33   Min.   :59.51  \n 1st Qu.:63.29   1st Qu.:71.97  \n Median :69.26   Median :75.48  \n Mean   :69.53   Mean   :76.78  \n 3rd Qu.:74.89   3rd Qu.:82.57  \n Max.   :87.87   Max.   :96.69  \n\n# Reshape the data to long format\nstudydata_long &lt;- studydata %&gt;%\n  pivot_longer(cols = c(\"before_update\", \"after_update\"), \n               names_to = \"Condition\", \n               values_to = \"Satisfaction\")\n\n# Create the boxplot\np &lt;- ggplot(studydata_long, aes(x = Condition, y = Satisfaction, fill = Condition)) +\n  geom_boxplot(alpha = 0.7) +\n  theme_cowplot() +\n  labs(title = \"Satisfaction Scores Before and After Update\", \n       x = \"Condition\", \n       y = \"Satisfaction Score\") +\n  scale_fill_manual(values = c(\"blue\", \"green\"))\n\np\n\n\n\n\n\n\n\n\n\n\n\n3.6.4 Performing the t-test\n\n3.6.4.1 Stata\n\nuse satisfaction_data_paired.dta\nttest before_update == after_update\n\nPaired t test\n------------------------------------------------------------------------------\nVariable |     Obs        Mean    Std. err.   Std. dev.   [95% conf. interval]\n---------+--------------------------------------------------------------------\nbefore~e |      30    70.30186    1.705283    9.340221    66.81417    73.78956\nafter_~e |      30    73.71915    2.408986    13.19456    68.79222    78.64608\n---------+--------------------------------------------------------------------\n    diff |      30    -3.41729    2.976942    16.30539   -9.505821    2.671241\n------------------------------------------------------------------------------\n     mean(diff) = mean(before_update - after_update)              t =  -1.1479\n H0: mean(diff) = 0                              Degrees of freedom =       29\n\n Ha: mean(diff) &lt; 0           Ha: mean(diff) != 0           Ha: mean(diff) &gt; 0\n Pr(T &lt; t) = 0.1302         Pr(|T| &gt; |t|) = 0.2604          Pr(T &gt; t) = 0.8698\n\n\n\n\n3.6.4.2 R\n\nstudydata &lt;- read.csv(\"satisfaction_data_paired.csv\")\nt.test(studydata$before_update, studydata$after_update, paired = TRUE)\n\n\n    Paired t-test\n\ndata:  studydata$before_update and studydata$after_update\nt = -2.8692, df = 29, p-value = 0.007601\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -12.425597  -2.083245\nsample estimates:\nmean difference \n      -7.254421 \n\n\n\n\n\n3.6.5 Interpretation\n\nP-value: Indicates whether the difference in means is statistically significant.\nConfidence Interval: It can be adjusted from the default 95% to another level if needed (but simply use 95% in case you are in doubt).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>t-test</span>"
    ]
  },
  {
    "objectID": "ttest.html#explanation-of-relevant-terms",
    "href": "ttest.html#explanation-of-relevant-terms",
    "title": "3  t-test",
    "section": "3.7 Explanation of Relevant Terms",
    "text": "3.7 Explanation of Relevant Terms\n\n\n\n\n\n\n\n\nTerm\nDefinition\nCommon Misconception\n\n\n\n\nP-value\nThe probability of obtaining test results at least as extreme as the results actually observed, under the assumption that the null hypothesis is true.\nThe p-value is the probability that the null hypothesis is true.\n\n\nConfidence Interval\nA range of values, derived from the sample data, that is believed to contain the true parameter value with a certain probability. The most common level of confidence is 95%, but this can be adjusted (e.g., to 90% or 99%) depending on the analysis.\nA 95% confidence interval means there is a 95% probability that the true parameter lies within the interval.\n\n\nT-statistic\nA ratio of the departure of the estimated value of a parameter from its hypothesized value to its standard error. The degrees of freedom (df) are the number of independent values that can vary in an analysis without breaking any constraints.\nThe t-statistic directly tells us the probability of the null hypothesis being true.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>t-test</span>"
    ]
  },
  {
    "objectID": "ttest.html#interpretation-questions",
    "href": "ttest.html#interpretation-questions",
    "title": "3  t-test",
    "section": "3.8 Interpretation Questions",
    "text": "3.8 Interpretation Questions\n\nWhat does a significant p-value indicate in the context of this t-test?\n\n\nShow/Hide Solution 1\n\n\nSolution 1: A significant p-value indicates that the observed data is unlikely under the null hypothesis. This suggests that there is evidence against the null hypothesis, implying a statistically significant difference between the satisfaction scores of the two groups (for independent samples) or before and after the update (for paired samples). However, it does not measure the probability that the null hypothesis is true or false.\n\n\nHow would you interpret the confidence interval in this analysis?\n\n\nShow/Hide Solution 2\n\n\nSolution 2: The confidence interval provides a range of values that, based on the sample data, is likely to contain the true mean difference. If we were to repeat the experiment many times, we would expect a specified proportion (e.g., 95%) of these intervals to contain the true mean difference. It does not mean that there is a 95% probability that the true mean difference lies within this specific interval. The most common confidence level is 95%, but it can be adjusted depending on the requirements of the analysis.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>t-test</span>"
    ]
  },
  {
    "objectID": "ttest.html#effect-sizes-for-t-tests",
    "href": "ttest.html#effect-sizes-for-t-tests",
    "title": "3  t-test",
    "section": "3.9 Effect Sizes for t-tests",
    "text": "3.9 Effect Sizes for t-tests\nEffect sizes are a crucial part of reporting t-test results because they provide information on the magnitude of the difference between groups or conditions, beyond just the statistical significance. Below, we discuss the common effect sizes to report for Independent Samples t-tests and Paired Samples t-tests. The most popular effect size to report for t-tests is Cohen’s d.\nThe interpretation guidelines for effect sizes such as Cohen’s d and the correlation coefficient (r) are based on widely accepted conventions in the field of psychology and social sciences. These conventions were originally proposed by Jacob Cohen in his foundational work on statistical power analysis.\nCautionary notes from Jacob Cohen regarding his proposed guidelines on effect sizes can be found in his book Statistical Power Analysis for the Behavioral Sciences (Cohen 1988) 3 and subsequent paper A Power Primer (Cohen 1992) 4. Cohen emphasized that the guidelines he provided for interpreting effect sizes (i.e., small, medium, and large) were meant to be rough, arbitrary conventions rather than rigid rules. He also proposed that a medium effect size should be visible without the need for statistical tools, though this expectation may not be practical across the diverse fields of research that apply these guidelines. Additionally, Cohen emphasized that these benchmarks are intended for use only when more precise estimates specific to the particular area of study are not available.\nCalculating Cohen’s d for Independent Samples t-test:\n\nR:\n\nTo calculate Cohen’s d for an Independent Samples t-test in R, you can use the effsize package, which provides a reliable implementation.\n\n# We need to use the dataset with the independent groups\n# Regenerating the dataset to make sure we have the right one\nset.seed(123)\nn &lt;- 30\nold_design &lt;- rnorm(n, mean = 70, sd = 10)\nnew_design &lt;- rnorm(n, mean = 75, sd = 10)\nstudydata_independent &lt;- data.frame(\n  group = rep(c(\"Old Design\", \"New Design\"), each = n),\n  satisfaction = c(old_design, new_design)\n)\n\n\n# Note: Use the dataset with independent samples: studydata_long\n\n# Compute cohen's d\ncohen_d &lt;- cohen.d(satisfaction ~ group, data = studydata_independent, pooled = TRUE)\ncat(\" Cohen's d: \", cohen_d$estimate)\n\n Cohen's d:  0.7963098\n\n\n\nStata:\n\nStata doesn’t have a built-in command to directly calculate Cohen’s d, but it can be calculated using the following steps:\n\n* Make sure the appropriate dataset is loaded (e.g. use DATASET_NAME)\n* Assuming the data is already loaded in Stata\nttest satisfaction, by(group)\n\n* Calculate manually\ngen pooled_sd = sqrt(((r(sd_1)^2) * (r(N_1) - 1) + (r(sd_2)^2) * (r(N_2) - 1)) / (r(N_1) + r(N_2) - 2))\ngen cohen_d = (r(mu_1) - r(mu_2)) / pooled_sd\ndisplay cohen_d\n\nno variables defined\nr(111);\n\nr(111);\n\n\n\n\n\n\n\n\n\n\nEffect Size\nRequired Information\nHow to Find It in Articles\n\n\n\n\nCohen’s d\nMeans of both groups, standard deviations, sample sizes\nLook for mean differences, standard deviations, and sample sizes in the results section of articles. Typically, these are presented in tables or described in the text.\n\n\n\nCalculating Effect Sizes for Paired Samples t-test:\n\nR:\n\n\n# We need to use the dataset with the dependent data\n# Regenerating the dataset to make sure we have the right one\nset.seed(123)\nn &lt;- 30\nbefore_update &lt;- rnorm(n, mean = 70, sd = 10)\nafter_update &lt;- rnorm(n, mean = 75, sd = 10)\nstudydata_paired &lt;- data.frame(\n  user_id = 1:n,\n  before_update = before_update,\n  after_update = after_update\n)\n\n\n# Calculate the mean difference and standard deviation of the differences\nmean_diff &lt;- mean(studydata_paired$before_update - studydata_paired$after_update)\nsd_diff &lt;- sd(studydata_paired$before_update - studydata_paired$after_update)\n\n# Calculate Cohen's d\ncohen_d_paired &lt;- mean_diff / sd_diff\n\ncat(\"Cohen's d = \",cohen_d_paired)\n\nCohen's d =  -0.5238355\n\n\nTo calculate the correlation coefficient (r):\n\n# Perform the paired t-test\nt_test &lt;- t.test(studydata_paired$before_update, studydata_paired$after_update, paired = TRUE)\n\n# Extract values from object of test output\nt_statistic &lt;- t_test$statistic %&gt;% unname\ndegfreedom &lt;- t_test$parameter %&gt;% unname\n\n# Calculate the correlation coefficient\nr_value &lt;- t_statistic / sqrt(t_statistic^2 + degfreedom)\n\ncat(\"r = \",r_value)\n\nr =  -0.4702152\n\n\n\nStata:\n\n\n* Make sure the appropriate dataset is loaded (e.g. use DATASET_NAME)\n* Perform the paired t-test\nttest before_update == after_update\n\n* Calculate Cohen s d manually\ngen mean_diff = r(mu_1) - r(mu_2)\ngen sd_diff = sqrt(r(sd_1)^2 + r(sd_2)^2 - 2 * r(sd_1) * r(sd_2) * r(rho))\ngen cohen_d_paired = mean_diff / sd_diff\ndisplay cohen_d_paired\n\nno variables defined\nr(111);\n\nr(111);\n\n\nTo calculate the correlation coefficient (r):\n\n* Calculate correlation coefficient\ngen r_value = r(t) / sqrt(r(t)^2 + r(df))\ndisplay r_value\n\n0\n\n\n\n\n\n\n\n\n\n\nEffect Size\nRequired Information\nHow to Find It in Articles\n\n\n\n\nCohen’s d (paired)\nMean difference, standard deviation of differences\nLook for mean differences and standard deviations of the differences between conditions. These are usually reported in the results section.\n\n\nCorrelation coefficient (r)\nt-statistic, degrees of freedom\nThe t-statistic and degrees of freedom are typically found in the results section, often in a table summarizing the t-test results.\n\n\n\n\n\n\n\n\n\n\n\n\nEffect Size Measure\nSmall\nMedium\nLarge\n\n\n\n\nCohen’s d (Independent or Paired)\n0.2\n0.5\n0.8\n\n\nCorrelation coefficient (r)\n0.1\n0.3\n0.5\n\n\n\n\n3.9.1 Differences Between Paired and Independent Effect Size Calculations\n\nIndependent Samples t-test: Cohen’s d is calculated using the pooled standard deviation of the two independent groups. The formula assumes that the two groups are independent and do not share any subjects.\nPaired Samples t-test: Cohen’s d for paired samples is calculated using the standard deviation of the differences between paired observations. This accounts for the fact that the same subjects are measured twice, and thus the observations are not independent.\n\nThe correlation coefficient (r) in paired samples t-tests can also provide insight into the strength of the relationship between the two sets of observations, which is not applicable in independent samples designs.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>t-test</span>"
    ]
  },
  {
    "objectID": "ttest.html#r-vs.-stata-commands",
    "href": "ttest.html#r-vs.-stata-commands",
    "title": "3  t-test",
    "section": "3.10 R vs. Stata Commands",
    "text": "3.10 R vs. Stata Commands\n\n3.10.1 Statistical Analysis Commands\n\n\n\n\n\n\n\n\nStep\nR Command\nStata Command\n\n\n\n\nDescriptive Statistics\nsummary(studydata$satisfaction)\nsummarize satisfaction\n\n\nBox Plot\nggplot(studydata, aes(x = group, y = satisfaction)) + geom_boxplot()\ngraph box satisfaction, over(group)\n\n\nT-Test (Independent)\nt.test(satisfaction ~ group, data = studydata, var.equal = TRUE)\nttest satisfaction, by(group)\n\n\nT-Test (Paired)\nt.test(studydata$before_update, studydata$after_update, paired = TRUE)\nttest before_update == after_update\n\n\n\n\n\n3.10.2 Data Simulation Commands\n\n\n\n\n\n\n\n\nStep\nR Command\nStata Command\n\n\n\n\nGenerate Data\nrnorm(n, mean, sd)\nrnormal(mean, sd)\n\n\nSave Data\nwrite.csv(studydata, \"satisfaction_data.csv\")\nsave satisfaction_data.dta, replace\n\n\n\n\n\n\n\nCohen, J. 1988. Statistical Power Analysis for the Behavioral Sciences. 2nd ed. Hillsdale, NJ: Lawrence Erlbaum Associates.\n\n\n———. 1992. “A Power Primer. Psychological Bulletin, 112 (1), 155–159.”\n\n\nStudent. 1908. “The Probable Error of a Mean.” Biometrika 6 (1): 1–25. http://www.jstor.org/stable/2331554.\n\n\nZiliak, Stephen T. 2008. “Retrospectives: Guinnessometrics: The Economic Foundation of “Student’s” t.” Journal of Economic Perspectives 22 (4): 199–216. https://doi.org/10.1257/jep.22.4.199.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>t-test</span>"
    ]
  },
  {
    "objectID": "ttest.html#footnotes",
    "href": "ttest.html#footnotes",
    "title": "3  t-test",
    "section": "",
    "text": "Student. (1908). The Probable Error of a Mean. Biometrika, 6(1), 1–25. https://doi.org/10.2307/2331554↩︎\nZiliak, Stephen T. 2008. “Retrospectives: Guinnessometrics: The Economic Foundation of”Student’s” t.” Journal of Economic Perspectives, 22 (4): 199–216.↩︎\nCohen, Jacob. 1988. Statistical Power Analysis for the BehavioralSciences. 2nd ed. Hillsdale, NJ: Lawrence Erlbaum Associates.↩︎\nCohen, J. (1992). A power primer. Psycholigcal Bulletin, 112 (1), 155–159.↩︎",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>t-test</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Cohen, J. 1988. Statistical Power Analysis for the Behavioral\nSciences. 2nd ed. Hillsdale, NJ: Lawrence Erlbaum Associates.\n\n\n———. 1992. “A Power Primer. Psychological Bulletin, 112 (1),\n155–159.”\n\n\nCox, Nicholas J. 2005. “A Brief History of Stata on Its 20th\nAnniversary.” The Stata Journal: Promoting Communications on\nStatistics and Stata 5 (1): 2–18. https://doi.org/10.1177/1536867x0500500102.\n\n\nPeng, Roger D. 2016. R Programming for Data Science. Leanpub\nVictoria, BC, Canada.\n\n\nStudent. 1908. “The Probable Error of a Mean.”\nBiometrika 6 (1): 1–25. http://www.jstor.org/stable/2331554.\n\n\nZiliak, Stephen T. 2008. “Retrospectives: Guinnessometrics: The\nEconomic Foundation of “Student’s”\nt.” Journal of Economic\nPerspectives 22 (4): 199–216. https://doi.org/10.1257/jep.22.4.199.",
    "crumbs": [
      "References"
    ]
  }
]